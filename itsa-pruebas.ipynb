{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":14043030,"datasetId":8915656,"databundleVersionId":14821695},{"sourceType":"datasetVersion","sourceId":13969086,"datasetId":8844408,"databundleVersionId":14743007},{"sourceType":"datasetVersion","sourceId":13832742,"datasetId":8809736,"databundleVersionId":14592041},{"sourceType":"datasetVersion","sourceId":14819623,"datasetId":9477299,"databundleVersionId":15676455},{"sourceType":"datasetVersion","sourceId":14730051,"datasetId":9412631,"databundleVersionId":15577883},{"sourceType":"modelInstanceVersion","sourceId":748224,"databundleVersionId":15661435,"modelInstanceId":571394,"modelId":583706,"isSourceIdPinned":false}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade ipython\n!pip install --upgrade pyriemann","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T20:03:52.500645Z","iopub.execute_input":"2026-02-27T20:03:52.501472Z","iopub.status.idle":"2026-02-27T20:03:59.538551Z","shell.execute_reply.started":"2026-02-27T20:03:52.501442Z","shell.execute_reply":"2026-02-27T20:03:59.537619Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (9.10.0)\nRequirement already satisfied: decorator>=4.3.2 in /usr/local/lib/python3.12/dist-packages (from ipython) (4.4.2)\nRequirement already satisfied: ipython-pygments-lexers>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython) (1.1.1)\nRequirement already satisfied: jedi>=0.18.1 in /usr/local/lib/python3.12/dist-packages (from ipython) (0.19.2)\nRequirement already satisfied: matplotlib-inline>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from ipython) (0.2.1)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython) (4.9.0)\nRequirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.12/dist-packages (from ipython) (3.0.52)\nRequirement already satisfied: pygments>=2.11.0 in /usr/local/lib/python3.12/dist-packages (from ipython) (2.19.2)\nRequirement already satisfied: stack_data>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from ipython) (0.6.3)\nRequirement already satisfied: traitlets>=5.13.0 in /usr/local/lib/python3.12/dist-packages (from ipython) (5.14.3)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.18.1->ipython) (0.8.5)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.6.0)\nRequirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython) (2.2.1)\nRequirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython) (3.0.1)\nRequirement already satisfied: pure-eval in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython) (0.2.3)\nCollecting pyriemann\n  Downloading pyriemann-0.10-py2.py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from pyriemann) (2.0.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pyriemann) (1.16.3)\nRequirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.12/dist-packages (from pyriemann) (1.6.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from pyriemann) (1.5.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from pyriemann) (3.10.0)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24->pyriemann) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyriemann) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyriemann) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyriemann) (4.61.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyriemann) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyriemann) (25.0)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyriemann) (11.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyriemann) (3.3.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyriemann) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->pyriemann) (1.17.0)\nDownloading pyriemann-0.10-py2.py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyriemann\nSuccessfully installed pyriemann-0.10\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"%%writefile ITSA.py\n\nimport numpy as np\nimport torch\nfrom typing import Dict, Optional, Union\n\n# PyRiemann utilities\nfrom pyriemann.utils.mean import mean_riemann, mean_logeuclid\nfrom pyriemann.utils.base import invsqrtm, sqrtm\nfrom pyriemann.tangentspace import TangentSpace\n\n# sklearn / scipy\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.linalg import orthogonal_procrustes\n\n\ndef to_spd_np(A: np.ndarray, eps: float = 1e-10) -> np.ndarray:\n    \"\"\"\n    Fuerza SPD en NumPy: simetriza, eleva autovalores < eps y reconstruye.\n    A: (n,n) np.ndarray\n    Devuelve: (n,n) np.ndarray SPD\n    \"\"\"\n    A = 0.5 * (A + A.T)\n    w, V = np.linalg.eigh(A)\n    w = np.clip(w, eps, None)\n    return (V * w) @ V.T\n\n\n@torch.no_grad()\ndef to_spd_torch(A: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n    \"\"\"\n    Fuerza SPD en Torch (GPU/CPU):\n    - Soporta (..., n, n)\n    - Simetriza, 'eigen-floor' y reconstruye con eigh batched.\n    \"\"\"\n    A = 0.5 * (A + A.transpose(-1, -2))\n    w, V = torch.linalg.eigh(A)  # (..., n), (..., n, n)\n    w = torch.clamp(w, min=eps)\n    A_spd = (V * w.unsqueeze(-2)) @ V.transpose(-1, -2)\n    A_spd = 0.5 * (A_spd + A_spd.transpose(-1, -2))  # por si redondeos\n    return A_spd\n\n\n@torch.no_grad()\ndef cov_from_signal_torch(x: torch.Tensor, eps: float = 1e-4) -> torch.Tensor:\n    \"\"\"\n    Calcula la covarianza de canales C = (X^T X) / (T-1) a partir de una\n    señal temporal X de forma (T, C), centrada por canal en el tiempo.\n\n    Args\n    -----\n    :param x: torch.Tensor, forma (T, C)\n      Señal temporal (T muestras, C canales).\n    :param eps: 1e-6\n    Returns\n    -------\n    C: torch.Tensor, forma (C, C)\n      Matriz de covarianza de canales.\n    \"\"\"\n    if x.dim() != 2:\n        raise ValueError(f\"x_np debe ser 2D (T,C); recibido: {tuple(x.shape)}\")\n    # Centrado por canal en el eje temporal\n    x0 = x - x.mean(dim=0, keepdim=True)  # (T, C)\n    T = max(1, x0.shape[0] - 1)\n    C = (x0.transpose(0, 1) @ x0) / T  # (C, C)\n    C = C + eps * torch.eye(C.shape[0], device=C.device, dtype=C.dtype)\n    return to_spd_torch(C)\n\n\ndef _as_numpy(x: Union[np.ndarray, torch.Tensor]) -> np.ndarray:\n    \"\"\"\n    Asegura np.ndarray (CPU). Si es Torch, hace .detach().cpu().numpy().\n    \"\"\"\n    if isinstance(x, np.ndarray):\n        return x\n    if torch.is_tensor(x):\n        return x.detach().cpu().numpy()\n    raise TypeError(f\"Tipo no soportado: {type(x)}\")\n\n\nclass ITSA:\n    \"\"\"\n    ITSA para señales multicanal (p. ej., EEG) con dos APIs:\n    1) API de características (igual que la versión original):\n       - fit(covs, labels, subjects, train_idx)\n       - transform(covs, subjects) -> Z_rot (espacio tangente)\n    2) API de señales (nueva):\n       - transform_signals(x, subjects) -> señales con la MISMA forma\n         que la entrada, tras aplicar un filtro espacial por sujeto que\n         implementa los 3 pasos: recentrado, escalado y alineación\n         supervisada (derivada en TS pero aplicada en dominio de señal).\n\n    Notas:\n    - No modifica el modelo downstream; devuelve (B,T,C) o (B,1,C,T).\n    - Las rotaciones se aprenden SOLO con TRAIN; en val/test se usa\n      un único filtro por sujeto.\n    \"\"\"\n\n    def __init__(\n        self,\n        subject_eps: float = 1e-10,\n        mean_tol: float = 1e-6,\n        mean_maxiter: int = 50,\n        unit_trace_per_subject: bool = True,\n    ) -> None:\n        self.subject_eps = subject_eps\n        self.mean_tol = mean_tol\n        self.mean_maxiter = mean_maxiter\n        self.unit_trace_per_subject = unit_trace_per_subject  # normalización de cada traza (opcional)\n\n        # Artefactos aprendidos\n        self.M_inv_sqrt_: Dict[int, np.ndarray] = {}\n        self.reference_G_: Optional[np.ndarray] = None\n        self.ts_: Optional[TangentSpace] = None\n        self.scaler_: Optional[StandardScaler] = None\n        self.Rs_: Dict[int, np.ndarray] = {}\n        self.A_filters_: Optional[Dict[int, np.ndarray]] = None\n\n        # NUEVO\n        self.mu_global_: Dict[int, np.ndarray = {}\n\n        # Caché GPU de filtros convertidos a Torch por (sujeto, device, dtype)\n        self._filters_cache: Dict[tuple, torch.Tensor] = {}\n\n    # ---------------- Paso 1: medias por sujeto + recentrado ----------------\n    def _fit_subject_means(self, covs: np.ndarray, subjects: np.ndarray, train_idx: np.ndarray) -> None:\n        N = covs.shape[0]\n        mask_tr = np.zeros(N, dtype=bool)\n        mask_tr[train_idx] = True\n        for s in np.unique(subjects):\n            s = int(s)\n            m = (subjects == s)\n            m_tr = m & mask_tr\n            covs_s_tr = covs[m_tr] if np.any(m_tr) else covs[m]\n            if self.unit_trace_per_subject:\n                tr = np.trace(covs_s_tr, axis1=1, axis2=2).reshape(-1, 1, 1)\n                covs_s_tr = covs_s_tr / np.maximum(tr, 1e-12)\n            M_init = mean_logeuclid(covs_s_tr)\n            M = mean_riemann(covs_s_tr, init=M_init, tol=self.mean_tol, maxiter=self.mean_maxiter)\n            self.M_inv_sqrt_[s] = invsqrtm(M)\n\n    def _apply_subject_recentering_np(self, covs: np.ndarray, subjects: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Recentrado por sujeto en NumPy: C' = M_s^{-1/2} C M_s^{-1/2}, con\n        asegurado SPD antes y después por robustez numérica.\n        \"\"\"\n        out = np.empty_like(covs)\n        for i, (C, s) in enumerate(zip(covs, subjects)):\n            s = int(s)\n            Cc = to_spd_np(C, eps=self.subject_eps)\n            Minv = self.M_inv_sqrt_[s]\n            out[i] = to_spd_np(Minv @ Cc @ Minv, eps=self.subject_eps)\n        return out\n\n    # -------- Paso 2–3: referencia G, TS(G) y estandarización (TRAIN) -------\n    def _fit_reference_tspace_and_scaler(self, covs_rec: np.ndarray, train_idx: np.ndarray) -> None:\n        mask_tr = np.zeros(covs_rec.shape[0], dtype=bool)\n        mask_tr[train_idx] = True\n        covs_tr = covs_rec[mask_tr]\n        G_init = mean_logeuclid(covs_tr)\n        G = mean_riemann(covs_tr, init=G_init, tol=self.mean_tol, maxiter=self.mean_maxiter)\n\n        ts = TangentSpace(metric='riemann')\n        ts.fit(covs_tr)\n        ts.reference_ = G\n\n        Z_tr = ts.transform(covs_tr)\n        scaler = StandardScaler(with_mean=True, with_std=True).fit(Z_tr)\n        self.reference_G_, self.ts_, self.scaler_ = G, ts, scaler\n\n    # ------------ Paso 4: Rotaciones supervisadas por sujeto (TRAIN) ---------\n    def _fit_subject_rotations(\n        self,\n        covs_rec: np.ndarray,\n        labels: np.ndarray,\n        subjects: np.ndarray,\n        train_idx: np.ndarray,\n    ) -> None:\n        assert self.ts_ is not None and self.scaler_ is not None\n        mask_tr = np.zeros(covs_rec.shape[0], dtype=bool)\n        mask_tr[train_idx] = True\n\n        Z_tr = self.ts_.transform(covs_rec[mask_tr])\n        Z_tr_std = self.scaler_.transform(Z_tr)\n        y_tr = labels[mask_tr]\n        s_tr = subjects[mask_tr]\n\n        # Centroides globales por clase (en TRAIN y estandarizados)\n        # CAMBIO AQUÍ\n        self.mu_global_ = {int(k): Z_tr_std[y_tr == k].mean(axis=0) for k in np.unique(y_tr)}\n        d = Z_tr_std.shape[1]\n        self.Rs_.clear()\n\n        for s in np.unique(s_tr):\n            s = int(s)\n            m = (s_tr == s)\n            Zs, ys = Z_tr_std[m], y_tr[m]\n            Ks = np.unique(ys)\n            if Ks.size < 2:\n                self.Rs_[s] = np.eye(d)\n                continue\n            # CAMBIO AQUÍ\n            A = np.stack([self.mu_global_[int(k)] for k in Ks], 0)\n            B = np.stack([Zs[ys == k].mean(axis=0) for k in Ks], 0)\n            R, _ = orthogonal_procrustes(B, A)\n            self.Rs_[s] = R if R.shape == (d, d) else np.eye(d)\n\n    # --------------------------- API clásica (features) ----------------------\n    def fit(\n        self,\n        covs: Union[np.ndarray, torch.Tensor],\n        labels: Union[np.ndarray, torch.Tensor],\n        subjects: Union[np.ndarray, torch.Tensor],\n        train_idx: Union[np.ndarray, torch.Tensor],\n    ):\n        \"\"\"\n        Ajusta ITSA usando SOLO TRAIN.\n        Acepta covs/labels/subjects/train_idx en NumPy o Torch.\n        Internamente convierte a NumPy (CPU) para PyRiemann/Sklearn.\n        \"\"\"\n        covs_np = _as_numpy(covs).astype(np.float64)  # (N,C,C)\n        labels_np = _as_numpy(labels).astype(np.int64).reshape(-1)\n        subjects_np = _as_numpy(subjects).astype(np.int64).reshape(-1)\n        train_idx_np = _as_numpy(train_idx).astype(np.int64).reshape(-1)\n\n        self._fit_subject_means(covs_np, subjects_np, train_idx_np)\n        covs_rec = self._apply_subject_recentering_np(covs_np, subjects_np)\n        self._fit_reference_tspace_and_scaler(covs_rec, train_idx_np)\n        self._fit_subject_rotations(covs_rec, labels_np, subjects_np, train_idx_np)\n\n        # Derivar filtros espaciales por sujeto (para transform_signals en GPU)\n        self._derive_subject_filters(covs_rec, labels_np, subjects_np, train_idx_np)\n\n        # Limpia caché (por si ya existía de otra corrida)\n        self._filters_cache.clear()\n        return self\n\n    def transform(\n        self,\n        covs: Union[np.ndarray, torch.Tensor],\n        subjects: Union[np.ndarray, torch.Tensor],\n    ) -> np.ndarray:\n        \"\"\"\n        Devuelve características ITSA (TS estandarizado y rotado).\n        Acepta covs/subjects en NumPy o Torch, y retorna NumPy (para coherencia con TS/Sklearn).\n        \"\"\"\n        assert self.ts_ is not None and self.scaler_ is not None\n\n        covs_np = _as_numpy(covs)\n        subjects_np = _as_numpy(subjects).astype(np.int64).reshape(-1)\n\n        # Recentrado por sujeto en NumPy (robusto y coherente con fit)\n        covs_rec = self._apply_subject_recentering_np(covs_np, subjects_np)\n\n        # TS -> estandarización -> rotación por sujeto\n        Z = self.ts_.transform(covs_rec)\n        Z_std = self.scaler_.transform(Z)\n        Z_rot = Z_std.copy()\n        for s, R in self.Rs_.items():\n            m = (subjects_np == s)\n            if np.any(m):\n                Z_rot[m] = Z_rot[m] @ R\n        return Z_rot\n\n    # FUNCIÓN ENTERA NUEVA !!!!!\n    def adapt_subject(\n        self,\n        covs: np.ndarray,\n        labels: np.ndarray,\n        subjects: np.ndarray,\n        train_idx: np.ndarray,\n    ):\n        \"\"\"\n        Adapta el espacio ITSA pre-entrenado a un NUEVO sujeto usando sus datos de calibración.\n        \"\"\"\n        covs_np = _as_numpy(covs).astype(np.float64)\n        labels_np = _as_numpy(labels).astype(np.int64).reshape(-1)\n        subjects_np = _as_numpy(subjects).astype(np.int64).reshape(-1)\n        train_idx_np = _as_numpy(train_idx).astype(np.int64).reshape(-1)\n\n        mask_tr = np.zeros(covs_np.shape[0], dtype=bool)\n        mask_tr[train_idx_np] = True\n\n        for s in np.unique(subjects_np):\n            s = int(s)\n            m = (subjects_np == s)\n            m_tr = m & mask_tr\n            covs_s_tr = covs_np[m_tr] if np.any(m_tr) else covs_np[m]\n\n            # 1. Media del sujeto nuevo y recentrado\n            if self.unit_trace_per_subject:\n                tr = np.trace(covs_s_tr, axis1=1, axis2=2).reshape(-1, 1, 1)\n                covs_s_tr = covs_s_tr / np.maximum(tr, 1e-12)\n\n            M_init = mean_logeuclid(covs_s_tr)\n            M = mean_riemann(covs_s_tr, init=M_init, tol=self.mean_tol, maxiter=self.mean_maxiter)\n            self.M_inv_sqrt_[s] = invsqrtm(M)\n\n            Cc = np.empty_like(covs_s_tr)\n            for i, C in enumerate(covs_s_tr):\n                C_spd = to_spd_np(C, eps=self.subject_eps)\n                Cc[i] = to_spd_np(self.M_inv_sqrt_[s] @ C_spd @ self.M_inv_sqrt_[s], eps=self.subject_eps)\n\n            # 2. Proyección al TS CONGELADO de los sujetos base\n            Z_tr = self.ts_.transform(Cc)\n            Z_tr_std = self.scaler_.transform(Z_tr)\n            ys = labels_np[m_tr] if np.any(m_tr) else labels_np[m]\n\n            # 3. Rotación supervisada hacia los centroides CONGELADOS\n            Ks = np.unique(ys)\n            d = Z_tr_std.shape[1]\n            valid_Ks = [k for k in Ks if int(k) in self.mu_global_] # Solo clases que conocemos\n            \n            if len(valid_Ks) < 2:\n                self.Rs_[s] = np.eye(d)\n            else:\n                A = np.stack([self.mu_global_[int(k)] for k in valid_Ks], 0) # Destino (Global)\n                B = np.stack([Z_tr_std[ys == k].mean(axis=0) for k in valid_Ks], 0) # Origen (Sujeto Nuevo)\n                R, _ = orthogonal_procrustes(B, A)\n                self.Rs_[s] = R if R.shape == (d, d) else np.eye(d)\n\n            # 4. Derivar el filtro final (A_s) para el Transformer\n            Gs_init = mean_logeuclid(Cc)\n            Cbar_rec_s = mean_riemann(Cc, init=Gs_init, tol=self.mean_tol, maxiter=self.mean_maxiter)\n\n            mu_s = Z_tr_std.mean(axis=0, keepdims=False).reshape(1, -1)\n            mu_rot = (mu_s @ self.Rs_[s].T)\n            mu_unstd = self.scaler_.inverse_transform(mu_rot)\n            G_target_s = self.ts_.inverse_transform(mu_unstd)[0]\n\n            W_s = invsqrtm(Cbar_rec_s) @ sqrtm(G_target_s)\n            self.A_filters_[s] = to_spd_np(self.M_inv_sqrt_[s] @ W_s)\n\n        self._filters_cache.clear() # Limpiamos caché GPU\n        return self\n\n    # --------------------- API de señales ------------------------------------\n    def _derive_subject_filters(\n        self,\n        covs_rec: np.ndarray,\n        labels: np.ndarray,\n        subjects: np.ndarray,\n        train_idx: np.ndarray,\n    ) -> None:\n        \"\"\"\n        Construye un filtro espacial único por sujeto:\n        A_s = M_s^{-1/2} * W_s,\n        donde W_s recolorea la media recentrada del sujeto hacia la\n        covarianza objetivo inducida por la rotación supervisada en TS.\n        \"\"\"\n        assert self.ts_ is not None and self.scaler_ is not None and self.reference_G_ is not None\n\n        N = covs_rec.shape[0]\n        mask_tr = np.zeros(N, dtype=bool)\n        mask_tr[train_idx] = True\n\n        Z_tr = self.ts_.transform(covs_rec[mask_tr])\n        Z_tr_std = self.scaler_.transform(Z_tr)\n        y_tr = labels[mask_tr]\n        s_tr = subjects[mask_tr]\n\n        self.A_filters_ = {}\n        for s in np.unique(s_tr):\n            s = int(s)\n            m = (s_tr == s)\n\n            # Media recentrada en SPD (del sujeto, TRAIN)\n            covs_s_rec = covs_rec[mask_tr][m]\n            Gs_init = mean_logeuclid(covs_s_rec)\n            Cbar_rec_s = mean_riemann(covs_s_rec, init=Gs_init, tol=self.mean_tol, maxiter=self.mean_maxiter)\n\n            # Media global del sujeto en TS (estandarizado) y rotación supervisada\n            mu_s = Z_tr_std[m].mean(axis=0, keepdims=False).reshape(1, -1)\n            R = self.Rs_.get(s, None)\n            if R is None:\n                R = np.eye(mu_s.shape[1])\n            mu_rot = (mu_s @ R.T)                  # (1, d)\n            mu_unstd = self.scaler_.inverse_transform(mu_rot)  # (1, d)\n            G_target_s = self.ts_.inverse_transform(mu_unstd)[0]  # (C, C)\n\n            # Recoloring: desde Cbar_rec_s hacia G_target_s\n            Cbar_rec_s_isqrt = invsqrtm(Cbar_rec_s)\n            G_target_s_sqrt = sqrtm(G_target_s)\n            W_s = Cbar_rec_s_isqrt @ G_target_s_sqrt\n\n            Minv = self.M_inv_sqrt_.get(s, None)\n            if Minv is None:\n                Minv = np.eye(W_s.shape[0])\n            A_s = Minv @ W_s\n\n            # Estabilización numérica (nota: esto impone simetría/SPD)\n            self.A_filters_[s] = to_spd_np(A_s)\n\n    @torch.no_grad()\n    def transform_signals(self, x: torch.Tensor, subjects: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Aplica el filtro espacial por sujeto y devuelve la MISMA forma que x.\n        x: torch.Tensor con forma (B,T,C), (B,1,C,T) o (T,C)\n        subjects: torch.LongTensor con ids de sujeto (B,) o escalar si x es 2D\n        \"\"\"\n        if isinstance(x, np.ndarray):\n            x = torch.from_numpy(x)\n\n        device = x.device\n        dtype = x.dtype\n\n        # Normalizar a (B,T,C)\n        squeeze_4d = False\n        if x.dim() == 4:  # (B,1,C,T)\n            squeeze_4d = True\n            B, _, C, T = x.shape\n            x_ = x.squeeze(1).transpose(1, 2)  # -> (B,T,C)\n        elif x.dim() == 3:  # (B,T,C)\n            x_ = x\n            B, T, C = x_.shape\n        elif x.dim() == 2:  # (T,C) -> (1,T,C)\n            x_ = x.unsqueeze(0)\n            B, T, C = x_.shape\n        else:\n            raise ValueError(f\"Forma no soportada: {tuple(x.shape)}\")\n\n        if not torch.is_tensor(subjects):\n            subjects = torch.tensor([int(subjects)], device=device)\n        elif subjects.dim() == 0:\n            subjects = subjects.view(1)\n\n        # Aplicar A_s por lote con caché GPU\n        out = []\n        for b in range(B):\n            s = int(subjects[b].item())\n            key = (s, device, dtype)\n\n            # Intentamos recuperar el filtro ya convertido y en el device correcto\n            A_t = self._filters_cache.get(key)\n            if A_t is None:\n                # Cargamos el filtro desde el diccionario de NumPy (learned in fit)\n                A_np = self.A_filters_.get(s, None) if self.A_filters_ is not None else None\n                if A_np is None:\n                    A_t = torch.eye(C, device=device, dtype=dtype)\n                else:\n                    A_t = torch.from_numpy(A_np).to(device=device, dtype=dtype)\n                self._filters_cache[key] = A_t  # guardamos en caché para el próximo batch\n\n            # Aplicamos el filtro: (T,C) @ (C,C) -> (T,C)\n            xb = x_[b] @ A_t\n            out.append(xb)\n\n        Xout = torch.stack(out, dim=0)  # (B,T,C)\n\n        # Volver a la forma original\n        if squeeze_4d:\n            return Xout.transpose(1, 2).unsqueeze(1)  # (B,1,C,T)\n        if x.dim() == 2:\n            return Xout.squeeze(0)  # (T,C)\n        return Xout\n\n\n# ------------------------------ Integrador minimalista ------------------------------\nimport torch as _torch  # alias local para evitar sombra de nombre\n\nclass ITSAIntegrator:\n    \"\"\"\n    Capa de integración para usar ITSA con cambios mínimos en el script principal.\n    - from_dataset(...): realiza todo el ajuste (fit) leyendo dataset + splits.\n    - transform_batch(x, subjects): aplica ITSA por sujeto y devuelve la MISMA forma que x.\n    \"\"\"\n    def __init__(self, itsa: ITSA):\n        self._itsa = itsa\n\n    @classmethod\n    def from_dataset(cls, dataset, splits_path: str, split_num: int = 0):\n        \"\"\"\n        Lee los splits desde `splits_path`, replica el mismo filtro 450<=L<=600 que usa Splitter,\n        construye las covarianzas por ensayo con el MISMO recorte temporal que hace EEGDataset.__getitem__,\n        y ajusta ITSA usando SOLO TRAIN.\n        \"\"\"\n        import numpy as _np\n        import torch as _t\n\n        loaded = _t.load(splits_path)\n        splitnames = [\"train\", \"val\", \"test\"]\n\n        # Replica el filtro de Splitter: mantener indices con 450 <= L <= 600 (en datos crudos)\n        def _valid_idx(i: int) -> bool:\n            eeg_raw = dataset.data[i][\"eeg\"]  # tensor crudo (C, T_raw)\n            L = eeg_raw.size(1)\n            return (L >= 450) and (L <= 600)\n\n        covs_list, labels_list, subjects_list, split_order = [], [], [], []\n\n        for sp in splitnames:\n            idxs = loaded[\"splits\"][split_num][sp]\n            idxs = [i for i in idxs if _valid_idx(i)]  # mismo filtro que Splitter\n\n            for i in idxs:\n                # Usa el __getitem__ del dataset para respetar el recorte temporal actual (time_low, time_high)\n                eeg, _label = dataset[i]  # (T,C) para transformer | (1,C,T) para EEGChannelNet\n                if eeg.dim() == 3:        # (1,C,T) -> (T,C)\n                    eeg2d = eeg.squeeze(0).transpose(0, 1)\n                else:\n                    eeg2d = eeg\n\n                C = cov_from_signal_torch(eeg2d).cpu().numpy()  # (C,C) SPD\n                covs_list.append(C)\n\n                labels_list.append(int(dataset.data[i][\"label\"]))\n                subjects_list.append(int(dataset.data[i][\"subject\"]))\n                split_order.append(sp)\n\n        covs = _np.stack(covs_list, axis=0)                       # (N, C, C)\n        labels = _np.asarray(labels_list, dtype=_np.int64)         # (N,)\n        subjects = _np.asarray(subjects_list, dtype=_np.int64)     # (N,)\n        train_idx = _np.asarray([k for k, s in enumerate(split_order) if s == \"train\"], dtype=_np.int64)\n\n        itsa = ITSA().fit(covs=covs, labels=labels, subjects=subjects, train_idx=train_idx)\n        return cls(itsa)\n\n    # CLASE ENTEROA NUEVA !!!!!!!\n    def adapt_from_dataset(self, dataset, splits_path: str, split_num: int = 0):\n        \"\"\"\n        Lee los datos del nuevo sujeto y adapta los filtros de ITSA a él.\n        \"\"\"\n        import numpy as _np\n        import torch as _t\n\n        loaded = _t.load(splits_path)\n        splitnames = [\"train\", \"val\", \"test\"]\n\n        def _valid_idx(i: int) -> bool:\n            eeg_raw = dataset.data[i][\"eeg\"]\n            L = eeg_raw.size(1)\n            return (L >= 450) and (L <= 600)\n\n        covs_list, labels_list, subjects_list, split_order = [], [], [], []\n\n        for sp in splitnames:\n            idxs = loaded[\"splits\"][split_num][sp]\n            idxs = [i for i in idxs if _valid_idx(i)]\n\n            for i in idxs:\n                eeg, _label = dataset[i]\n                if eeg.dim() == 3:\n                    eeg2d = eeg.squeeze(0).transpose(0, 1)\n                else:\n                    eeg2d = eeg\n\n                C = cov_from_signal_torch(eeg2d.double(), eps=1e-4).cpu().numpy()\n                covs_list.append(C)\n\n                labels_list.append(int(dataset.data[i][\"label\"]))\n                subjects_list.append(int(dataset.data[i][\"subject\"]))\n                split_order.append(sp)\n\n        covs = _np.stack(covs_list, axis=0)\n        labels = _np.asarray(labels_list, dtype=_np.int64)\n        subjects = _np.asarray(subjects_list, dtype=_np.int64)\n        train_idx = _np.asarray([k for k, s in enumerate(split_order) if s == \"train\"], dtype=_np.int64)\n\n        # Aplicamos la nueva función matemática\n        self._itsa.adapt_subject(covs=covs, labels=labels, subjects=subjects, train_idx=train_idx)\n        return self\n\n    @_torch.no_grad()\n    def transform_batch(self, x: _torch.Tensor, subjects: _torch.Tensor) -> _torch.Tensor:\n        \"\"\"\n        Aplica ITSA por sujeto. Conserva la forma de x:\n        - (B,T,C) -> (B,T,C)\n        - (B,1,C,T) -> (B,1,C,T)\n        \"\"\"\n        return self._itsa.transform_signals(x, subjects)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T20:03:59.540528Z","iopub.execute_input":"2026-02-27T20:03:59.540799Z","iopub.status.idle":"2026-02-27T20:03:59.580803Z","shell.execute_reply.started":"2026-02-27T20:03:59.540772Z","shell.execute_reply":"2026-02-27T20:03:59.580067Z"}},"outputs":[{"name":"stdout","text":"Overwriting ITSA.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T20:03:59.581734Z","iopub.execute_input":"2026-02-27T20:03:59.582036Z","iopub.status.idle":"2026-02-27T20:03:59.609542Z","shell.execute_reply.started":"2026-02-27T20:03:59.582004Z","shell.execute_reply":"2026-02-27T20:03:59.608847Z"}},"outputs":[{"name":"stdout","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"##### Define options\nimport argparse\n\nparser = argparse.ArgumentParser(description=\"Template\")\n# Dataset options\n\n# Data - Data needs to be pre-filtered and filtered data is available\n\n### BLOCK DESIGN ###\n# Data\nparser.add_argument('-ed', '--eeg-dataset', default=r\"/kaggle/input/datasets/marii04/eeg-datasets/eeg_55_95_std.pth\", help=\"EEG dataset path\") #55-95Hz\n# parser.add_argument('-ed', '--eeg-dataset', default=r\"data\\block\\eeg_5_95_std.pth\", help=\"EEG dataset path\")  # 5-95Hz\n# parser.add_argument('-ed', '--eeg-dataset', default=r\"data\\block\\eeg_14_70_std.pth\", help=\"EEG dataset path\") #14-70Hz\n# Splits\n#parser.add_argument('-sp', '--splits-path', default=r\"/kaggle/input/datasets/marii04/single-subject-splits/block_splits_by_single_subject_1.pth\", help=\"splits path\") #Subject 1\n#parser.add_argument('-sp', '--splits-path', default=r\"/kaggle/input/datasets/marii04/single-subject-splits/block_splits_by_single_subject23456.pth\", help=\"splits path\") #Subjects 2,3,4,5,6\nparser.add_argument('-sp', '--splits-path', default=r\"/kaggle/input/datasets/marii04/splits-all-subjects/block_splits_by_image_all.pth\", help=\"splits path\") #All subjects\n#parser.add_argument('-sp', '--splits-path', default=r\"/kaggle/input/datasets/marii04/splits-loso/block_splits_LOSO_subject6.pth\", help=\"splits path\") #LOSO\n\n\n### BLOCK DESIGN ###\n\nparser.add_argument('-sn', '--split-num', default=0, type=int, help=\"split number\")  # leave this always to zero.\n\n# Subject selecting\nparser.add_argument('-sub', '--subject', default=0, type=int,\n                    help=\"choose a subject from 1 to 6, default is 0 (all subjects)\")\n\n# Time options: select from 20 to 460 samples from EEG data\nparser.add_argument('-tl', '--time_low', default=20, type=float, help=\"lowest time value\")\nparser.add_argument('-th', '--time_high', default=460, type=float, help=\"highest time value\")\n\n# Model type/options\nparser.add_argument('-mt', '--model_type', default='transformer2',\n                    help='specify which generator should be used: lstm|EEGChannelNet')\n# It is possible to test out multiple deep classifiers:\n# - lstm is the model described in the paper \"Deep Learning Human Mind for Automated Visual Classification”, in CVPR 2017\n# - model10 is the model described in the paper \"Decoding brain representations by multimodal learning of neural activity and visual features\", TPAMI 2020\nparser.add_argument('-mp', '--model_params', default=['num_heads=4', 'num_layers=1', 'd_ff=512', 'd_model=128', 'dropout=0.4'], nargs='*', help='list of key=value pairs of model options')\n#parser.add_argument('--pretrained_net', default='', help=\"path to pre-trained net (to continue training)\")\nparser.add_argument('--pretrained_net', default='', help=\"path to pre-trained net (to continue training)\")\n\n# Training options\nparser.add_argument(\"-b\", \"--batch_size\", default=128, type=int, help=\"batch size\")\nparser.add_argument('-o', '--optim', default=\"Adam\", help=\"optimizer\")\nparser.add_argument('-lr', '--learning-rate', default=0.001, type=float, help=\"learning rate\")\nparser.add_argument('-lrdb', '--learning-rate-decay-by', default=0.95, type=float, help=\"learning rate decay factor\")\nparser.add_argument('-lrde', '--learning-rate-decay-every', default=10, type=int, help=\"learning rate decay period\")\nparser.add_argument('-dw', '--data-workers', default=4, type=int, help=\"data loading workers\")\nparser.add_argument('-e', '--epochs', default=200, type=int, help=\"training epochs\")\n#parser.add_argument('-do', '--dropout', default=0.2, type=float, help=\"dropout probability (overwrites model default)\")\n# Save options\nparser.add_argument('-sc', '--saveCheck', default=200, type=int, help=\"learning rate\")\n# Backend options\nparser.add_argument('--no-cuda', default=False, help=\"disable CUDA\", action=\"store_true\")\n\n# cargar objeto ITSA guardado\nparse.add_argument('--pretrained_itsa', default='', help=\"path to pre-trained itsa\")\n\n\n# Parse arguments\nopt = parser.parse_args(args=[])\nprint(opt)\n\nopt.time_low = int(opt.time_low)\nopt.time_high = int(opt.time_high)\n\n# Imports\nimport sys\nimport os\nimport random\nimport math\nimport time\nimport torch;\n\ntorch.utils.backcompat.broadcast_warning.enabled = True\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim\nimport torch.backends.cudnn as cudnn;\n\nimport torch.serialization\n\n# archivo ITSA\nfrom ITSA import ITSAIntegrator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-27T20:03:59.610995Z","iopub.execute_input":"2026-02-27T20:03:59.611494Z","iopub.status.idle":"2026-02-27T20:04:01.122458Z","shell.execute_reply.started":"2026-02-27T20:03:59.611471Z","shell.execute_reply":"2026-02-27T20:04:01.121890Z"}},"outputs":[{"name":"stdout","text":"Namespace(eeg_dataset='/kaggle/input/datasets/marii04/eeg-datasets/eeg_55_95_std.pth', splits_path='/kaggle/input/datasets/marii04/splits-all-subjects/block_splits_by_image_all.pth', split_num=0, subject=0, time_low=20, time_high=460, model_type='transformer2', model_params=['num_heads=4', 'num_layers=1', 'd_ff=512', 'd_model=128', 'dropout=0.4'], pretrained_net='', batch_size=128, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.95, learning_rate_decay_every=10, data_workers=4, epochs=200, saveCheck=200, no_cuda=False)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"cudnn.benchmark = True\nfrom scipy.fftpack import fft, rfft, fftfreq, irfft, ifft, rfftfreq\nfrom scipy import signal\nimport numpy as np\n# import models\nimport importlib\n\nimport shutil\n\n# path where Kaggle stores the uploaded model files\nKAGGLE_MODEL_DIR = \"/kaggle/input/models/marii04/transformer-carla/pytorch/default/1\"\n\n# create a local \"models\" folder\nos.makedirs(\"models\", exist_ok=True)\n\n# copy EEGChannelNet.py into models/\nsrc_model_file = os.path.join(KAGGLE_MODEL_DIR, \"transformer2.py\")\ndst_model_file = os.path.join(\"models\", \"transformer2.py\")\nif not os.path.exists(dst_model_file):\n    shutil.copy(src_model_file, dst_model_file)\n\n# copy layers.py into the proyect root\nsrc_layers_file = os.path.join(KAGGLE_MODEL_DIR, \"layers.py\")\ndst_layers_file = \"layers.py\"\nif not os.path.exists(dst_layers_file):\n    shutil.copy(src_layers_file, dst_layers_file)\n\n# add current directory to sys.path (so both root and models/ work)\nsys.path.append(os.getcwd())\n\n\nprint(\"Model and layers files copied and import path configured\")\n\nfrom models.transformer2 import Model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T20:04:01.123263Z","iopub.execute_input":"2026-02-27T20:04:01.123572Z","iopub.status.idle":"2026-02-27T20:04:01.336246Z","shell.execute_reply.started":"2026-02-27T20:04:01.123551Z","shell.execute_reply":"2026-02-27T20:04:01.335651Z"}},"outputs":[{"name":"stdout","text":"Model and layers files copied and import path configured\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Dataset class\nclass EEGDataset:\n\n    # Constructor\n    def __init__(self, eeg_signals_path):\n        # Load EEG signals\n        loaded = torch.load(eeg_signals_path)\n        if opt.subject != 0:\n            self.data = [loaded['dataset'][i] for i in range(len(loaded['dataset'])) if\n                         loaded['dataset'][i]['subject'] == opt.subject]\n        else:\n            self.data = loaded['dataset']\n        self.labels = loaded[\"labels\"]\n        self.images = loaded[\"images\"]\n\n        # Compute size\n        self.size = len(self.data)\n\n    # Get size\n    def __len__(self):\n        return self.size\n\n    # Get item\n    def __getitem__(self, i):\n        # Process EEG\n        eeg = self.data[i][\"eeg\"].float().t()\n        eeg = eeg[opt.time_low:opt.time_high, :]\n\n        if opt.model_type == \"EEGChannelNet\":\n            eeg = eeg.t()\n            eeg = eeg.view(1, 128, opt.time_high - opt.time_low)\n        # Get label\n        label = self.data[i][\"label\"]\n        # Return\n        return eeg, label\n\n\n# Splitter class\nclass Splitter:\n\n    def __init__(self, dataset, split_path, split_num=0, split_name=\"train\"):\n        # Set EEG dataset\n        self.dataset = dataset\n        # Load split\n        loaded = torch.load(split_path)\n        self.split_idx = loaded[\"splits\"][split_num][split_name]\n        # Filter data\n        self.split_idx = [i for i in self.split_idx if 450 <= self.dataset.data[i][\"eeg\"].size(1) <= 600]\n        # Compute size\n        self.size = len(self.split_idx)\n\n    # Get size\n    def __len__(self):\n        return self.size\n\n    # Get item\n    def __getitem__(self, i):\n        # Get sample from dataset\n        eeg, label = self.dataset[self.split_idx[i]]\n        subj = self.dataset.data[self.split_idx[i]][\"subject\"]\n        # Return\n        return eeg, label, subj\n\n# Load dataset\ndataset = EEGDataset(opt.eeg_dataset)\n# Create loaders\nloaders = {split: DataLoader(Splitter(dataset, split_path=opt.splits_path, split_num=opt.split_num, split_name=split),\n                             batch_size=opt.batch_size, drop_last=True, shuffle=True) for split in\n           [\"train\", \"val\", \"test\"]}\n\nif opt.pretrained_itsa != '':\n    itsa = torch.load(opt.pretrained_itsa)\n    itsa.adapt_from_dataset(dataset, splits_path=opt.splits_path, split_num=opt.split_num)\nelse:\n    itsa = ITSAIntegrator.from_dataset(dataset, splits_path=opt.splits_path, split_num=opt.split_num)\n\n# Load model\nmodel_options = {key: int(value) if value.isdigit() else (float(value) if value[0].isdigit() else value) for\n                 (key, value) in [x.split(\"=\") for x in opt.model_params]}\n# Create discriminator model/optimizer\nmodule = importlib.import_module(\"models.\" + opt.model_type)\nmodel = module.Model(**model_options)\n\n\noptimizer = getattr(torch.optim, opt.optim)(model.parameters(), lr=opt.learning_rate)\n# Learning rate scheduler (equivalente al learning_rate_decay_by para Adam)\nscheduler = torch.optim.lr_scheduler.StepLR(\n    optimizer,\n    step_size=opt.learning_rate_decay_every,\n    gamma=opt.learning_rate_decay_by\n)\n\n\n# Setup CUDA\nif not opt.no_cuda:\n    model.cuda()\n    print(\"Copied to CUDA\")\n\nif opt.pretrained_net != '':\n    torch.serialization.add_safe_globals([Model])\n    model = torch.load(opt.pretrained_net, weights_only=False)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=opt.learning_rate)  # nuevo LR\n    # Learning rate scheduler (equivalente al learning_rate_decay_by para Adam)\n    scheduler = torch.optim.lr_scheduler.StepLR(\n        optimizer,\n        step_size=opt.learning_rate_decay_every,\n        gamma=opt.learning_rate_decay_by\n    )\n\n\n    # probar LR 0.005\n    # disminuir LR_decay_by\n\n    \n    #for name, param in model.named_parameters():\n     #   print(f\"Parameter name: {name}, Trainable: {param.requires_grad}\")\n    \n    print(model)\n\n# initialize training,validation, test losses and accuracy list\nlosses_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\naccuracies_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\n\nbest_accuracy = 0\nbest_accuracy_val = 0\nbest_epoch = 0\n# Start training\n\npredicted_labels = []\ncorrect_labels = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T20:04:01.337122Z","iopub.execute_input":"2026-02-27T20:04:01.337371Z","iopub.status.idle":"2026-02-27T20:42:50.993832Z","shell.execute_reply.started":"2026-02-27T20:04:01.337349Z","shell.execute_reply":"2026-02-27T20:42:50.993143Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pyriemann/utils/mean.py:688: UserWarning: Convergence not reached\n  warnings.warn(\"Convergence not reached\")\n","output_type":"stream"},{"name":"stdout","text":"Copied to CUDA\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"for epoch in range(1, opt.epochs + 1):\n    # Initialize loss/accuracy variables\n    losses = {\"train\": 0, \"val\": 0, \"test\": 0}\n    accuracies = {\"train\": 0, \"val\": 0, \"test\": 0}\n    counts = {\"train\": 0, \"val\": 0, \"test\": 0}\n    # Adjust learning rate for SGD\n    if opt.optim == \"SGD\":\n        lr = opt.learning_rate * (opt.learning_rate_decay_by ** (epoch // opt.learning_rate_decay_every))\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n    # Process each split\n    for split in (\"train\", \"val\", \"test\"):\n        # Set network mode\n        if split == \"train\":\n            model.train()\n            torch.set_grad_enabled(True)\n        else:\n            model.eval()\n            torch.set_grad_enabled(False)\n        # Process all split batches\n        for i, (input, target, batch_subjects) in enumerate(loaders[split]):\n            # Check CUDA\n            if not opt.no_cuda:\n                input = input.to(\"cuda\") \n                target = target.to(\"cuda\")\n                batch_subjects = batch_subjects.to(\"cuda\")\n            # Forward\n            input = itsa.transform_batch(input, batch_subjects)\n            output = model(input)\n\n            # Compute loss\n            loss = F.cross_entropy(output, target)\n            losses[split] += loss.item()\n            # Compute accuracy\n            _, pred = output.data.max(1)\n            correct = pred.eq(target.data).sum().item()\n            accuracy = correct / input.data.size(0)\n            accuracies[split] += accuracy\n            counts[split] += 1\n            # Backward and optimize\n            if split == \"train\":\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n    # Print info at the end of the epoch\n    if accuracies[\"val\"] / counts[\"val\"] >= best_accuracy_val:\n        best_accuracy_val = accuracies[\"val\"] / counts[\"val\"]\n        best_accuracy = accuracies[\"test\"] / counts[\"test\"]\n        best_epoch = epoch\n\n    TrL, TrA, VL, VA, TeL, TeA = losses[\"train\"] / counts[\"train\"], accuracies[\"train\"] / counts[\"train\"], losses[\n        \"val\"] / counts[\"val\"], accuracies[\"val\"] / counts[\"val\"], losses[\"test\"] / counts[\"test\"], accuracies[\"test\"] / \\\n                                 counts[\"test\"]\n    print(\n        \"Model: {11} - Subject {12} - Time interval: [{9}-{10}]  [{9}-{10} Hz] - Epoch {0}: TrL={1:.4f}, TrA={2:.4f}, VL={3:.4f}, VA={4:.4f}, TeL={5:.4f}, TeA={6:.4f}, TeA at max VA = {7:.4f} at epoch {8:d}\".format(\n            epoch,\n            losses[\"train\"] / counts[\"train\"],\n            accuracies[\"train\"] / counts[\"train\"],\n            losses[\"val\"] / counts[\"val\"],\n            accuracies[\"val\"] / counts[\"val\"],\n            losses[\"test\"] / counts[\"test\"],\n            accuracies[\"test\"] / counts[\"test\"],\n            best_accuracy, best_epoch, opt.time_low, opt.time_high, opt.model_type, opt.subject))\n\n    losses_per_epoch['train'].append(TrL)\n    losses_per_epoch['val'].append(VL)\n    losses_per_epoch['test'].append(TeL)\n    accuracies_per_epoch['train'].append(TrA)\n    accuracies_per_epoch['val'].append(VA)\n    accuracies_per_epoch['test'].append(TeA)\n\n     # Update learning rate after each epoch\n    scheduler.step()\n\n    if epoch % opt.saveCheck == 0:\n        torch.save(model, '%s__subject%d_epoch_%d.pth' % (opt.model_type, opt.subject, epoch))\n\n        torch.save(itsa, 'itsa_pretrained_space.pth')\n        print(f\"Modelo y espacio ITSA guardados en la época {epoch}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T20:42:50.994652Z","iopub.execute_input":"2026-02-27T20:42:50.994892Z","iopub.status.idle":"2026-02-27T20:58:05.029113Z","shell.execute_reply.started":"2026-02-27T20:42:50.994869Z","shell.execute_reply":"2026-02-27T20:58:05.028362Z"}},"outputs":[{"name":"stdout","text":"Model: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 1: TrL=3.6447, TrA=0.0389, VL=3.3997, VA=0.0734, TeL=3.4344, TeA=0.0651, TeA at max VA = 0.0651 at epoch 1\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 2: TrL=3.0755, TrA=0.0868, VL=2.8127, VA=0.0844, TeL=2.8519, TeA=0.0792, TeA at max VA = 0.0792 at epoch 2\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 3: TrL=2.6762, TrA=0.1206, VL=2.5367, VA=0.1120, TeL=2.5222, TeA=0.1448, TeA at max VA = 0.1448 at epoch 3\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 4: TrL=2.4506, TrA=0.1622, VL=2.3583, VA=0.1568, TeL=2.3587, TeA=0.1656, TeA at max VA = 0.1656 at epoch 4\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 5: TrL=2.2882, TrA=0.1925, VL=2.2269, VA=0.2073, TeL=2.2215, TeA=0.1984, TeA at max VA = 0.1984 at epoch 5\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 6: TrL=2.1931, TrA=0.2185, VL=2.0975, VA=0.2156, TeL=2.0779, TeA=0.2234, TeA at max VA = 0.2234 at epoch 6\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 7: TrL=2.0926, TrA=0.2300, VL=2.0648, VA=0.2417, TeL=2.0556, TeA=0.2458, TeA at max VA = 0.2458 at epoch 7\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 8: TrL=2.0246, TrA=0.2605, VL=1.9762, VA=0.2490, TeL=1.9190, TeA=0.2620, TeA at max VA = 0.2620 at epoch 8\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 9: TrL=1.9556, TrA=0.2770, VL=1.8728, VA=0.3010, TeL=1.8551, TeA=0.2750, TeA at max VA = 0.2750 at epoch 9\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 10: TrL=1.9012, TrA=0.2949, VL=1.9378, VA=0.2573, TeL=1.8780, TeA=0.2703, TeA at max VA = 0.2750 at epoch 9\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 11: TrL=1.8518, TrA=0.2993, VL=1.9006, VA=0.2786, TeL=1.8218, TeA=0.2906, TeA at max VA = 0.2750 at epoch 9\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 12: TrL=1.7899, TrA=0.3310, VL=1.8576, VA=0.2938, TeL=1.8271, TeA=0.2964, TeA at max VA = 0.2750 at epoch 9\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 13: TrL=1.7611, TrA=0.3329, VL=1.8178, VA=0.3010, TeL=1.7735, TeA=0.3031, TeA at max VA = 0.3031 at epoch 13\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 14: TrL=1.7464, TrA=0.3419, VL=1.8100, VA=0.3047, TeL=1.7336, TeA=0.3380, TeA at max VA = 0.3380 at epoch 14\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 15: TrL=1.7056, TrA=0.3558, VL=1.8095, VA=0.3120, TeL=1.7200, TeA=0.3333, TeA at max VA = 0.3333 at epoch 15\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 16: TrL=1.6721, TrA=0.3604, VL=1.7670, VA=0.3203, TeL=1.7021, TeA=0.3448, TeA at max VA = 0.3448 at epoch 16\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 17: TrL=1.6488, TrA=0.3625, VL=1.8058, VA=0.3104, TeL=1.6922, TeA=0.3552, TeA at max VA = 0.3448 at epoch 16\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 18: TrL=1.6112, TrA=0.3722, VL=1.7658, VA=0.3422, TeL=1.7175, TeA=0.3375, TeA at max VA = 0.3375 at epoch 18\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 19: TrL=1.5860, TrA=0.3852, VL=1.6864, VA=0.3516, TeL=1.6420, TeA=0.3557, TeA at max VA = 0.3557 at epoch 19\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 20: TrL=1.5792, TrA=0.3948, VL=1.7147, VA=0.3547, TeL=1.6904, TeA=0.3563, TeA at max VA = 0.3563 at epoch 20\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 21: TrL=1.5398, TrA=0.4010, VL=1.6162, VA=0.3661, TeL=1.5954, TeA=0.3766, TeA at max VA = 0.3766 at epoch 21\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 22: TrL=1.4983, TrA=0.4158, VL=1.5909, VA=0.3682, TeL=1.5539, TeA=0.3656, TeA at max VA = 0.3656 at epoch 22\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 23: TrL=1.4957, TrA=0.4191, VL=1.6263, VA=0.3771, TeL=1.5446, TeA=0.3979, TeA at max VA = 0.3979 at epoch 23\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 24: TrL=1.4999, TrA=0.4187, VL=1.6231, VA=0.3828, TeL=1.5841, TeA=0.3839, TeA at max VA = 0.3839 at epoch 24\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 25: TrL=1.4473, TrA=0.4332, VL=1.6284, VA=0.3734, TeL=1.6062, TeA=0.3745, TeA at max VA = 0.3839 at epoch 24\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 26: TrL=1.4414, TrA=0.4442, VL=1.5727, VA=0.4000, TeL=1.5468, TeA=0.4031, TeA at max VA = 0.4031 at epoch 26\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 27: TrL=1.4173, TrA=0.4480, VL=1.5496, VA=0.4036, TeL=1.5288, TeA=0.4094, TeA at max VA = 0.4094 at epoch 27\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 28: TrL=1.4200, TrA=0.4481, VL=1.5685, VA=0.4052, TeL=1.5888, TeA=0.3859, TeA at max VA = 0.3859 at epoch 28\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 29: TrL=1.3956, TrA=0.4563, VL=1.5117, VA=0.4125, TeL=1.5195, TeA=0.4005, TeA at max VA = 0.4005 at epoch 29\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 30: TrL=1.3799, TrA=0.4569, VL=1.5341, VA=0.4156, TeL=1.4693, TeA=0.4052, TeA at max VA = 0.4052 at epoch 30\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 31: TrL=1.3656, TrA=0.4601, VL=1.6021, VA=0.3891, TeL=1.5698, TeA=0.4146, TeA at max VA = 0.4052 at epoch 30\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 32: TrL=1.3738, TrA=0.4613, VL=1.5638, VA=0.4193, TeL=1.5246, TeA=0.4062, TeA at max VA = 0.4062 at epoch 32\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 33: TrL=1.3388, TrA=0.4803, VL=1.6110, VA=0.4062, TeL=1.5121, TeA=0.4188, TeA at max VA = 0.4062 at epoch 32\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 34: TrL=1.3308, TrA=0.4768, VL=1.5424, VA=0.4161, TeL=1.5072, TeA=0.4203, TeA at max VA = 0.4062 at epoch 32\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 35: TrL=1.3062, TrA=0.4880, VL=1.5240, VA=0.4516, TeL=1.4595, TeA=0.4453, TeA at max VA = 0.4453 at epoch 35\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 36: TrL=1.2996, TrA=0.4908, VL=1.5158, VA=0.4260, TeL=1.4239, TeA=0.4521, TeA at max VA = 0.4453 at epoch 35\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 37: TrL=1.2980, TrA=0.4912, VL=1.5443, VA=0.4260, TeL=1.4934, TeA=0.4495, TeA at max VA = 0.4453 at epoch 35\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 38: TrL=1.2890, TrA=0.5018, VL=1.5333, VA=0.4240, TeL=1.4684, TeA=0.4339, TeA at max VA = 0.4453 at epoch 35\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 39: TrL=1.2896, TrA=0.4880, VL=1.5609, VA=0.4266, TeL=1.4695, TeA=0.4401, TeA at max VA = 0.4453 at epoch 35\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 40: TrL=1.2688, TrA=0.5003, VL=1.4490, VA=0.4500, TeL=1.4292, TeA=0.4464, TeA at max VA = 0.4453 at epoch 35\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 41: TrL=1.2408, TrA=0.5163, VL=1.4441, VA=0.4547, TeL=1.4116, TeA=0.4583, TeA at max VA = 0.4583 at epoch 41\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 42: TrL=1.2350, TrA=0.5140, VL=1.4658, VA=0.4417, TeL=1.4305, TeA=0.4432, TeA at max VA = 0.4583 at epoch 41\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 43: TrL=1.2135, TrA=0.5185, VL=1.4550, VA=0.4656, TeL=1.3751, TeA=0.4948, TeA at max VA = 0.4948 at epoch 43\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 44: TrL=1.2104, TrA=0.5263, VL=1.5279, VA=0.4349, TeL=1.5053, TeA=0.4443, TeA at max VA = 0.4948 at epoch 43\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 45: TrL=1.2064, TrA=0.5271, VL=1.5294, VA=0.4479, TeL=1.5072, TeA=0.4401, TeA at max VA = 0.4948 at epoch 43\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 46: TrL=1.1956, TrA=0.5300, VL=1.4287, VA=0.4724, TeL=1.4138, TeA=0.4766, TeA at max VA = 0.4766 at epoch 46\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 47: TrL=1.1967, TrA=0.5331, VL=1.4129, VA=0.4703, TeL=1.4162, TeA=0.4578, TeA at max VA = 0.4766 at epoch 46\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 48: TrL=1.1830, TrA=0.5388, VL=1.3904, VA=0.4823, TeL=1.3913, TeA=0.4771, TeA at max VA = 0.4771 at epoch 48\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 49: TrL=1.1696, TrA=0.5407, VL=1.4380, VA=0.4635, TeL=1.4131, TeA=0.4724, TeA at max VA = 0.4771 at epoch 48\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 50: TrL=1.1398, TrA=0.5539, VL=1.4442, VA=0.4615, TeL=1.4244, TeA=0.4698, TeA at max VA = 0.4771 at epoch 48\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 51: TrL=1.1305, TrA=0.5645, VL=1.4252, VA=0.4781, TeL=1.4256, TeA=0.4771, TeA at max VA = 0.4771 at epoch 48\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 52: TrL=1.1187, TrA=0.5645, VL=1.4267, VA=0.4745, TeL=1.4107, TeA=0.4849, TeA at max VA = 0.4771 at epoch 48\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 53: TrL=1.0974, TrA=0.5643, VL=1.5225, VA=0.4594, TeL=1.4648, TeA=0.4760, TeA at max VA = 0.4771 at epoch 48\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 54: TrL=1.0991, TrA=0.5689, VL=1.3950, VA=0.4880, TeL=1.3963, TeA=0.4672, TeA at max VA = 0.4672 at epoch 54\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 55: TrL=1.1013, TrA=0.5667, VL=1.3782, VA=0.5000, TeL=1.3778, TeA=0.4953, TeA at max VA = 0.4953 at epoch 55\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 56: TrL=1.0925, TrA=0.5689, VL=1.4552, VA=0.4635, TeL=1.4448, TeA=0.4974, TeA at max VA = 0.4953 at epoch 55\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 57: TrL=1.0804, TrA=0.5738, VL=1.4513, VA=0.4745, TeL=1.3985, TeA=0.4953, TeA at max VA = 0.4953 at epoch 55\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 58: TrL=1.0712, TrA=0.5757, VL=1.4603, VA=0.4620, TeL=1.3882, TeA=0.4927, TeA at max VA = 0.4953 at epoch 55\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 59: TrL=1.0654, TrA=0.5862, VL=1.3936, VA=0.5005, TeL=1.4078, TeA=0.4792, TeA at max VA = 0.4792 at epoch 59\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 60: TrL=1.0492, TrA=0.5900, VL=1.4202, VA=0.4990, TeL=1.4127, TeA=0.4922, TeA at max VA = 0.4792 at epoch 59\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 61: TrL=1.0443, TrA=0.5885, VL=1.3991, VA=0.4818, TeL=1.3613, TeA=0.4943, TeA at max VA = 0.4792 at epoch 59\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 62: TrL=1.0226, TrA=0.6105, VL=1.4080, VA=0.4958, TeL=1.3563, TeA=0.4906, TeA at max VA = 0.4792 at epoch 59\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 63: TrL=1.0094, TrA=0.6105, VL=1.3513, VA=0.5161, TeL=1.3112, TeA=0.5089, TeA at max VA = 0.5089 at epoch 63\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 64: TrL=1.0022, TrA=0.6047, VL=1.3839, VA=0.5083, TeL=1.3696, TeA=0.5073, TeA at max VA = 0.5089 at epoch 63\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 65: TrL=0.9993, TrA=0.6074, VL=1.3786, VA=0.5125, TeL=1.3593, TeA=0.5146, TeA at max VA = 0.5089 at epoch 63\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 66: TrL=0.9800, TrA=0.6216, VL=1.4890, VA=0.5036, TeL=1.4288, TeA=0.5141, TeA at max VA = 0.5089 at epoch 63\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 67: TrL=0.9994, TrA=0.6094, VL=1.3850, VA=0.5141, TeL=1.3851, TeA=0.5078, TeA at max VA = 0.5089 at epoch 63\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 68: TrL=0.9894, TrA=0.6133, VL=1.4322, VA=0.5125, TeL=1.4031, TeA=0.5016, TeA at max VA = 0.5089 at epoch 63\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 69: TrL=0.9622, TrA=0.6305, VL=1.3293, VA=0.5307, TeL=1.2913, TeA=0.5417, TeA at max VA = 0.5417 at epoch 69\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 70: TrL=0.9683, TrA=0.6263, VL=1.4436, VA=0.5182, TeL=1.3627, TeA=0.5203, TeA at max VA = 0.5417 at epoch 69\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 71: TrL=0.9551, TrA=0.6327, VL=1.3593, VA=0.5359, TeL=1.3614, TeA=0.5302, TeA at max VA = 0.5302 at epoch 71\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 72: TrL=0.9338, TrA=0.6384, VL=1.4043, VA=0.4911, TeL=1.3218, TeA=0.5240, TeA at max VA = 0.5302 at epoch 71\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 73: TrL=0.9351, TrA=0.6467, VL=1.3545, VA=0.5188, TeL=1.3415, TeA=0.5188, TeA at max VA = 0.5302 at epoch 71\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 74: TrL=0.9395, TrA=0.6411, VL=1.3876, VA=0.5203, TeL=1.3303, TeA=0.5344, TeA at max VA = 0.5302 at epoch 71\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 75: TrL=0.9215, TrA=0.6457, VL=1.3802, VA=0.5161, TeL=1.3302, TeA=0.5255, TeA at max VA = 0.5302 at epoch 71\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 76: TrL=0.9186, TrA=0.6505, VL=1.3770, VA=0.5193, TeL=1.3461, TeA=0.5276, TeA at max VA = 0.5302 at epoch 71\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 77: TrL=0.9059, TrA=0.6530, VL=1.5043, VA=0.5047, TeL=1.4413, TeA=0.4969, TeA at max VA = 0.5302 at epoch 71\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 78: TrL=0.9150, TrA=0.6458, VL=1.3717, VA=0.5339, TeL=1.3678, TeA=0.5141, TeA at max VA = 0.5302 at epoch 71\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 79: TrL=0.8991, TrA=0.6540, VL=1.4118, VA=0.5370, TeL=1.3836, TeA=0.5156, TeA at max VA = 0.5156 at epoch 79\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 80: TrL=0.8994, TrA=0.6561, VL=1.4603, VA=0.5109, TeL=1.3932, TeA=0.5219, TeA at max VA = 0.5156 at epoch 79\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 81: TrL=0.8875, TrA=0.6604, VL=1.4242, VA=0.5234, TeL=1.3525, TeA=0.5188, TeA at max VA = 0.5156 at epoch 79\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 82: TrL=0.8755, TrA=0.6632, VL=1.4113, VA=0.5385, TeL=1.3347, TeA=0.5339, TeA at max VA = 0.5339 at epoch 82\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 83: TrL=0.8675, TrA=0.6760, VL=1.4058, VA=0.5323, TeL=1.3466, TeA=0.5443, TeA at max VA = 0.5339 at epoch 82\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 84: TrL=0.8655, TrA=0.6748, VL=1.3479, VA=0.5427, TeL=1.3357, TeA=0.5526, TeA at max VA = 0.5526 at epoch 84\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 85: TrL=0.8597, TrA=0.6736, VL=1.3918, VA=0.5328, TeL=1.3515, TeA=0.5281, TeA at max VA = 0.5526 at epoch 84\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 86: TrL=0.8525, TrA=0.6758, VL=1.4228, VA=0.5198, TeL=1.3643, TeA=0.5281, TeA at max VA = 0.5526 at epoch 84\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 87: TrL=0.8423, TrA=0.6846, VL=1.4082, VA=0.5255, TeL=1.3647, TeA=0.5318, TeA at max VA = 0.5526 at epoch 84\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 88: TrL=0.8407, TrA=0.6832, VL=1.4169, VA=0.5396, TeL=1.3577, TeA=0.5443, TeA at max VA = 0.5526 at epoch 84\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 89: TrL=0.8192, TrA=0.6924, VL=1.4333, VA=0.5286, TeL=1.3550, TeA=0.5370, TeA at max VA = 0.5526 at epoch 84\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 90: TrL=0.8429, TrA=0.6755, VL=1.4228, VA=0.5266, TeL=1.3824, TeA=0.5344, TeA at max VA = 0.5526 at epoch 84\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 91: TrL=0.8214, TrA=0.6968, VL=1.4913, VA=0.5344, TeL=1.4421, TeA=0.5370, TeA at max VA = 0.5526 at epoch 84\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 92: TrL=0.8162, TrA=0.6900, VL=1.4382, VA=0.5474, TeL=1.3622, TeA=0.5437, TeA at max VA = 0.5437 at epoch 92\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 93: TrL=0.8037, TrA=0.7056, VL=1.4584, VA=0.5365, TeL=1.3693, TeA=0.5458, TeA at max VA = 0.5437 at epoch 92\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 94: TrL=0.8052, TrA=0.6997, VL=1.3905, VA=0.5615, TeL=1.3686, TeA=0.5516, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 95: TrL=0.8098, TrA=0.6966, VL=1.3751, VA=0.5448, TeL=1.3343, TeA=0.5443, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 96: TrL=0.7946, TrA=0.7046, VL=1.5088, VA=0.5276, TeL=1.4280, TeA=0.5365, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 97: TrL=0.7898, TrA=0.6991, VL=1.4207, VA=0.5245, TeL=1.3835, TeA=0.5495, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 98: TrL=0.7974, TrA=0.7006, VL=1.4210, VA=0.5531, TeL=1.4026, TeA=0.5510, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 99: TrL=0.7767, TrA=0.7121, VL=1.4459, VA=0.5448, TeL=1.4145, TeA=0.5297, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 100: TrL=0.7739, TrA=0.7068, VL=1.5178, VA=0.5385, TeL=1.4768, TeA=0.5396, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 101: TrL=0.7689, TrA=0.7166, VL=1.4571, VA=0.5490, TeL=1.4397, TeA=0.5380, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 102: TrL=0.7434, TrA=0.7251, VL=1.4753, VA=0.5328, TeL=1.4139, TeA=0.5312, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 103: TrL=0.7407, TrA=0.7258, VL=1.4432, VA=0.5474, TeL=1.4120, TeA=0.5401, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 104: TrL=0.7341, TrA=0.7240, VL=1.3982, VA=0.5578, TeL=1.3787, TeA=0.5453, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 105: TrL=0.7248, TrA=0.7355, VL=1.4318, VA=0.5510, TeL=1.3679, TeA=0.5620, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 106: TrL=0.7242, TrA=0.7320, VL=1.4627, VA=0.5474, TeL=1.3614, TeA=0.5563, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 107: TrL=0.7331, TrA=0.7256, VL=1.4724, VA=0.5510, TeL=1.4272, TeA=0.5615, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 108: TrL=0.7289, TrA=0.7349, VL=1.4688, VA=0.5432, TeL=1.3954, TeA=0.5568, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 109: TrL=0.7077, TrA=0.7408, VL=1.4470, VA=0.5500, TeL=1.3826, TeA=0.5589, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 110: TrL=0.7041, TrA=0.7461, VL=1.4939, VA=0.5406, TeL=1.4358, TeA=0.5490, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 111: TrL=0.7103, TrA=0.7360, VL=1.5223, VA=0.5292, TeL=1.4384, TeA=0.5495, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 112: TrL=0.6894, TrA=0.7434, VL=1.5492, VA=0.5464, TeL=1.4837, TeA=0.5370, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 113: TrL=0.6884, TrA=0.7456, VL=1.4745, VA=0.5526, TeL=1.4552, TeA=0.5427, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 114: TrL=0.6903, TrA=0.7440, VL=1.4937, VA=0.5458, TeL=1.4353, TeA=0.5464, TeA at max VA = 0.5516 at epoch 94\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 115: TrL=0.6793, TrA=0.7548, VL=1.4135, VA=0.5854, TeL=1.4095, TeA=0.5552, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 116: TrL=0.6883, TrA=0.7436, VL=1.4422, VA=0.5635, TeL=1.3877, TeA=0.5568, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 117: TrL=0.6703, TrA=0.7567, VL=1.4678, VA=0.5609, TeL=1.4165, TeA=0.5615, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 118: TrL=0.6777, TrA=0.7555, VL=1.4445, VA=0.5693, TeL=1.3790, TeA=0.5766, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 119: TrL=0.6503, TrA=0.7645, VL=1.5012, VA=0.5510, TeL=1.4246, TeA=0.5604, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 120: TrL=0.6797, TrA=0.7538, VL=1.3849, VA=0.5813, TeL=1.4227, TeA=0.5641, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 121: TrL=0.6510, TrA=0.7679, VL=1.4289, VA=0.5818, TeL=1.4283, TeA=0.5547, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 122: TrL=0.6637, TrA=0.7615, VL=1.4487, VA=0.5599, TeL=1.4731, TeA=0.5474, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 123: TrL=0.6598, TrA=0.7566, VL=1.4056, VA=0.5750, TeL=1.3658, TeA=0.5557, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 124: TrL=0.6580, TrA=0.7645, VL=1.4597, VA=0.5635, TeL=1.4111, TeA=0.5771, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 125: TrL=0.6486, TrA=0.7617, VL=1.4498, VA=0.5667, TeL=1.4302, TeA=0.5578, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 126: TrL=0.6380, TrA=0.7670, VL=1.4390, VA=0.5786, TeL=1.3879, TeA=0.5630, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 127: TrL=0.6396, TrA=0.7631, VL=1.4232, VA=0.5750, TeL=1.3875, TeA=0.5734, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 128: TrL=0.6305, TrA=0.7768, VL=1.4722, VA=0.5615, TeL=1.3876, TeA=0.5599, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 129: TrL=0.6211, TrA=0.7766, VL=1.4341, VA=0.5828, TeL=1.4069, TeA=0.5661, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 130: TrL=0.6265, TrA=0.7705, VL=1.4990, VA=0.5589, TeL=1.5050, TeA=0.5531, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 131: TrL=0.6362, TrA=0.7698, VL=1.5364, VA=0.5521, TeL=1.4904, TeA=0.5589, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 132: TrL=0.6214, TrA=0.7792, VL=1.5169, VA=0.5724, TeL=1.4217, TeA=0.5563, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 133: TrL=0.6224, TrA=0.7818, VL=1.4819, VA=0.5672, TeL=1.4098, TeA=0.5693, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 134: TrL=0.6206, TrA=0.7796, VL=1.4923, VA=0.5714, TeL=1.4748, TeA=0.5677, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 135: TrL=0.6204, TrA=0.7738, VL=1.5389, VA=0.5625, TeL=1.4607, TeA=0.5542, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 136: TrL=0.6106, TrA=0.7807, VL=1.5345, VA=0.5615, TeL=1.4800, TeA=0.5620, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 137: TrL=0.6062, TrA=0.7815, VL=1.5384, VA=0.5625, TeL=1.4598, TeA=0.5599, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 138: TrL=0.5885, TrA=0.7936, VL=1.5134, VA=0.5698, TeL=1.4591, TeA=0.5760, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 139: TrL=0.6054, TrA=0.7852, VL=1.5265, VA=0.5604, TeL=1.4745, TeA=0.5609, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 140: TrL=0.5931, TrA=0.7925, VL=1.5024, VA=0.5802, TeL=1.4946, TeA=0.5630, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 141: TrL=0.5858, TrA=0.7974, VL=1.5260, VA=0.5620, TeL=1.4731, TeA=0.5698, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 142: TrL=0.5820, TrA=0.7957, VL=1.5624, VA=0.5693, TeL=1.5302, TeA=0.5552, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 143: TrL=0.5894, TrA=0.7936, VL=1.5109, VA=0.5672, TeL=1.4932, TeA=0.5635, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 144: TrL=0.5778, TrA=0.7950, VL=1.4995, VA=0.5687, TeL=1.4808, TeA=0.5687, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 145: TrL=0.5849, TrA=0.7966, VL=1.4575, VA=0.5839, TeL=1.4889, TeA=0.5714, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 146: TrL=0.5787, TrA=0.7940, VL=1.5215, VA=0.5828, TeL=1.4697, TeA=0.5766, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 147: TrL=0.5823, TrA=0.7940, VL=1.5892, VA=0.5594, TeL=1.5573, TeA=0.5521, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 148: TrL=0.5619, TrA=0.8041, VL=1.4548, VA=0.5776, TeL=1.4519, TeA=0.5734, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 149: TrL=0.5482, TrA=0.8082, VL=1.5104, VA=0.5844, TeL=1.5221, TeA=0.5615, TeA at max VA = 0.5552 at epoch 115\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 150: TrL=0.5541, TrA=0.8083, VL=1.5167, VA=0.5859, TeL=1.4830, TeA=0.5792, TeA at max VA = 0.5792 at epoch 150\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 151: TrL=0.5501, TrA=0.8106, VL=1.5502, VA=0.5635, TeL=1.5269, TeA=0.5661, TeA at max VA = 0.5792 at epoch 150\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 152: TrL=0.5451, TrA=0.8091, VL=1.5413, VA=0.5734, TeL=1.4823, TeA=0.5771, TeA at max VA = 0.5792 at epoch 150\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 153: TrL=0.5447, TrA=0.8083, VL=1.5261, VA=0.5755, TeL=1.5335, TeA=0.5755, TeA at max VA = 0.5792 at epoch 150\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 154: TrL=0.5308, TrA=0.8216, VL=1.4829, VA=0.5974, TeL=1.5016, TeA=0.5755, TeA at max VA = 0.5755 at epoch 154\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 155: TrL=0.5378, TrA=0.8143, VL=1.5688, VA=0.5823, TeL=1.5884, TeA=0.5672, TeA at max VA = 0.5755 at epoch 154\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 156: TrL=0.5561, TrA=0.8004, VL=1.6321, VA=0.5672, TeL=1.6037, TeA=0.5745, TeA at max VA = 0.5755 at epoch 154\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 157: TrL=0.5455, TrA=0.8067, VL=1.5213, VA=0.5859, TeL=1.4724, TeA=0.5854, TeA at max VA = 0.5755 at epoch 154\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 158: TrL=0.5225, TrA=0.8158, VL=1.4991, VA=0.5917, TeL=1.4926, TeA=0.5672, TeA at max VA = 0.5755 at epoch 154\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 159: TrL=0.5183, TrA=0.8246, VL=1.5287, VA=0.5823, TeL=1.5204, TeA=0.5698, TeA at max VA = 0.5755 at epoch 154\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 160: TrL=0.5128, TrA=0.8194, VL=1.5128, VA=0.5865, TeL=1.4898, TeA=0.5698, TeA at max VA = 0.5755 at epoch 154\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 161: TrL=0.5237, TrA=0.8193, VL=1.5054, VA=0.5818, TeL=1.5445, TeA=0.5729, TeA at max VA = 0.5755 at epoch 154\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 162: TrL=0.5198, TrA=0.8180, VL=1.4806, VA=0.6010, TeL=1.5019, TeA=0.5771, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 163: TrL=0.5046, TrA=0.8272, VL=1.4805, VA=0.5896, TeL=1.5243, TeA=0.5813, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 164: TrL=0.5015, TrA=0.8305, VL=1.5355, VA=0.5875, TeL=1.4796, TeA=0.5880, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 165: TrL=0.5111, TrA=0.8238, VL=1.5631, VA=0.5938, TeL=1.5359, TeA=0.5755, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 166: TrL=0.5077, TrA=0.8230, VL=1.6045, VA=0.5786, TeL=1.5576, TeA=0.5750, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 167: TrL=0.5067, TrA=0.8299, VL=1.5126, VA=0.5974, TeL=1.4885, TeA=0.5875, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 168: TrL=0.4894, TrA=0.8284, VL=1.5891, VA=0.5807, TeL=1.5410, TeA=0.5760, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 169: TrL=0.4871, TrA=0.8356, VL=1.5594, VA=0.5891, TeL=1.5179, TeA=0.5911, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 170: TrL=0.4871, TrA=0.8303, VL=1.5403, VA=0.5885, TeL=1.5191, TeA=0.5859, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 171: TrL=0.4718, TrA=0.8376, VL=1.5447, VA=0.5911, TeL=1.4773, TeA=0.5865, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 172: TrL=0.4727, TrA=0.8410, VL=1.5214, VA=0.6005, TeL=1.4801, TeA=0.5922, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 173: TrL=0.4675, TrA=0.8422, VL=1.6266, VA=0.5859, TeL=1.5788, TeA=0.5724, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 174: TrL=0.4757, TrA=0.8333, VL=1.5943, VA=0.5938, TeL=1.5592, TeA=0.5719, TeA at max VA = 0.5771 at epoch 162\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 175: TrL=0.4645, TrA=0.8451, VL=1.5316, VA=0.6062, TeL=1.5235, TeA=0.5823, TeA at max VA = 0.5823 at epoch 175\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 176: TrL=0.4667, TrA=0.8411, VL=1.6128, VA=0.5906, TeL=1.6554, TeA=0.5740, TeA at max VA = 0.5823 at epoch 175\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 177: TrL=0.4613, TrA=0.8450, VL=1.6002, VA=0.5870, TeL=1.5445, TeA=0.5802, TeA at max VA = 0.5823 at epoch 175\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 178: TrL=0.4630, TrA=0.8441, VL=1.5927, VA=0.6036, TeL=1.5813, TeA=0.5844, TeA at max VA = 0.5823 at epoch 175\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 179: TrL=0.4456, TrA=0.8523, VL=1.5960, VA=0.6000, TeL=1.5562, TeA=0.5833, TeA at max VA = 0.5823 at epoch 175\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 180: TrL=0.4626, TrA=0.8393, VL=1.5937, VA=0.5979, TeL=1.5951, TeA=0.5776, TeA at max VA = 0.5823 at epoch 175\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 181: TrL=0.4556, TrA=0.8385, VL=1.5703, VA=0.5995, TeL=1.5713, TeA=0.5828, TeA at max VA = 0.5823 at epoch 175\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 182: TrL=0.4429, TrA=0.8565, VL=1.5548, VA=0.6062, TeL=1.5147, TeA=0.5849, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 183: TrL=0.4426, TrA=0.8499, VL=1.5780, VA=0.5953, TeL=1.5707, TeA=0.5839, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 184: TrL=0.4512, TrA=0.8456, VL=1.6105, VA=0.5995, TeL=1.5251, TeA=0.5943, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 185: TrL=0.4340, TrA=0.8576, VL=1.6472, VA=0.5771, TeL=1.6066, TeA=0.5740, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 186: TrL=0.4331, TrA=0.8569, VL=1.5760, VA=0.5938, TeL=1.5428, TeA=0.5859, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 187: TrL=0.4335, TrA=0.8540, VL=1.6413, VA=0.5807, TeL=1.5977, TeA=0.5927, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 188: TrL=0.4195, TrA=0.8596, VL=1.5557, VA=0.6021, TeL=1.5502, TeA=0.5911, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 189: TrL=0.4209, TrA=0.8605, VL=1.5211, VA=0.5995, TeL=1.5953, TeA=0.5813, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 190: TrL=0.4299, TrA=0.8582, VL=1.6585, VA=0.5943, TeL=1.6211, TeA=0.5760, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 191: TrL=0.4177, TrA=0.8625, VL=1.5591, VA=0.5948, TeL=1.5499, TeA=0.5948, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 192: TrL=0.4138, TrA=0.8604, VL=1.6110, VA=0.5948, TeL=1.6148, TeA=0.5823, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 193: TrL=0.4104, TrA=0.8677, VL=1.6191, VA=0.5891, TeL=1.5941, TeA=0.5792, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 194: TrL=0.4155, TrA=0.8627, VL=1.6444, VA=0.5901, TeL=1.6187, TeA=0.5833, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 195: TrL=0.4091, TrA=0.8638, VL=1.6106, VA=0.5979, TeL=1.5906, TeA=0.5859, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 196: TrL=0.4173, TrA=0.8608, VL=1.6102, VA=0.5922, TeL=1.5790, TeA=0.5901, TeA at max VA = 0.5849 at epoch 182\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 197: TrL=0.4062, TrA=0.8674, VL=1.6092, VA=0.6083, TeL=1.6455, TeA=0.5714, TeA at max VA = 0.5714 at epoch 197\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 198: TrL=0.3996, TrA=0.8697, VL=1.6221, VA=0.6047, TeL=1.6110, TeA=0.5906, TeA at max VA = 0.5714 at epoch 197\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 199: TrL=0.3998, TrA=0.8669, VL=1.6543, VA=0.5885, TeL=1.6899, TeA=0.5615, TeA at max VA = 0.5714 at epoch 197\nModel: transformer2 - Subject 0 - Time interval: [20-460]  [20-460 Hz] - Epoch 200: TrL=0.3906, TrA=0.8718, VL=1.6084, VA=0.6005, TeL=1.5627, TeA=0.5885, TeA at max VA = 0.5714 at epoch 197\n","output_type":"stream"}],"execution_count":12}]}